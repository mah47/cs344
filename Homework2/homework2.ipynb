{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1 of Homework2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Probability:  0.6075324675324676\n",
      "Word probabilities: {'I': 0.99, 'am': 0.99, 'spam': 0.99, 'do': 0.27272727272727276, 'not': 0.99, 'like': 0.27272727272727276, 'green': 0.01, 'eggs': 0.01, 'and': 0.01, 'ham': 0.01}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nIt makes it Bayesian because it determines the probabilities of individual words and uses them\\nto determine the overall probability. If the program shows that the words spam then the email is spam because the\\nprobability is conditional.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Name: Marcos Hernandez (mah47)\n",
    "CS 344\n",
    "Homework 2\n",
    "'''\n",
    "\n",
    "class SpamFilter:\n",
    "\n",
    "    def __init__(self, corpus1, corpus2, strings):\n",
    "        self.spam_corpus = self.corpusWords(corpus1)\n",
    "        self.spam2_corpus = self.corpusWords(corpus2)\n",
    "        self.fusedCorpus = strings\n",
    "        self.corpusLength = 0\n",
    "        self.corpusAmount = self.corpusMix()\n",
    "        self.corpusAlgo = {}\n",
    "\n",
    "    def corpusWords(self, strings):\n",
    "        corpus = []\n",
    "        for words in strings:\n",
    "            for corpWord in words:\n",
    "                corpus.append(corpWord)\n",
    "        return corpus\n",
    "\n",
    "    def corpusMix(self):\n",
    "        dictionary = {}\n",
    "        for words in self.fusedCorpus:\n",
    "            for corpWord in words:\n",
    "                if corpWord not in dictionary.keys():\n",
    "                    dictionary[corpWord] = 0\n",
    "                self.corpusLength += 1\n",
    "                dictionary[corpWord] += 1\n",
    "        return dictionary\n",
    "\n",
    "    def result(self):\n",
    "        # print(self.corpusAmount)\n",
    "        # print(self.spam_corpus)\n",
    "        # print(self.fusedCorpus)\n",
    "        # print(self.spam2_corpus)\n",
    "        corps = 0\n",
    "        for words in self.fusedCorpus:\n",
    "            for corpWord in words:\n",
    "                spam = 0\n",
    "                filterCorps = 0\n",
    "                if corpWord in self.spam2_corpus:\n",
    "                    spam = 2 * self.corpusAmount[corpWord]\n",
    "                if corpWord in self.spam_corpus:\n",
    "                    filterCorps = self.corpusAmount[corpWord]\n",
    "\n",
    "                if spam + filterCorps >= 1:\n",
    "                    corpusCode = max(0.01, min(0.99, min(1.0, filterCorps / len(self.spam_corpus))\n",
    "                                               / (min(1.0, spam / len(self.spam2_corpus)) +\n",
    "                                                  min(1.0, filterCorps / len(self.spam_corpus)))))\n",
    "                    corps += corpusCode\n",
    "                    self.corpusAlgo[corpWord] = corpusCode\n",
    "        return corps / self.corpusLength\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "    ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "    corpus_sample = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"]]\n",
    "    filterCorpus = SpamFilter(spam_corpus, ham_corpus, corpus_sample)\n",
    "    print(\"Spam Probability: \", filterCorpus.result())\n",
    "    print(\"Word probabilities: \" + str(filterCorpus.corpusAlgo))\n",
    "\n",
    "'''\n",
    "It makes it Bayesian because it determines the probabilities of individual words and uses them\n",
    "to determine the overall probability. If the program shows that the words spam then the email is spam because the\n",
    "probability is conditional.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 of Homework2\n",
    "a. from tools.aima.probablity import BayesNet, enumeration_ask, elimination_ask, gibbs_ask\n",
    "b. Used 4 True/False variables. In total there 16 independent variables\n",
    "c. The total for possible value in the variable are 9 for the Bayes Network. Wetgrass shows 4 variables, Cloudy shows 1 variables, Rain shows 2 variables, and Sprinkler shows 2 variables. 4 + 2 + 2 + 1 = 9 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False: 0.5, True: 0.5\n",
      "False: 0.9, True: 0.1\n",
      "False: 0.952, True: 0.0476\n",
      "False: 0.01, True: 0.99\n",
      "False: 0.639, True: 0.361\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Name: Marcos Hernandez (mah47)\n",
    "CS 344\n",
    "'''\n",
    "\n",
    "\n",
    "from tools.aima.probability import BayesNet, enumeration_ask, elimination_ask, gibbs_ask\n",
    "\n",
    "# Utility variables\n",
    "T, F = True, False\n",
    "\n",
    "# From AIMA code (probability.py) - Fig. 14.2 - burglary example\n",
    "climate = BayesNet([\n",
    "    ('Cloudy', '', 0.5),\n",
    "    ('Sprinkler', 'Cloudy', {T: 0.1, F: 0.5}),\n",
    "    ('Rain', 'Cloudy', {T: 0.8, F: 0.2}),\n",
    "    ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99, (T, F): 0.9, (F, T): 0.9, (F, F): 0.0})\n",
    "])\n",
    "\n",
    "'''\n",
    "i. P(Cloudy) = 0.5\n",
    "= 0.5, 0.5\n",
    "'''\n",
    "\n",
    "print(enumeration_ask('Cloudy', dict(), climate).show_approx())\n",
    "\n",
    "'''\n",
    "ii.P(Sprinker | cloudy) = 0.1\n",
    "= 0.1, 0.9\n",
    "'''\n",
    "print(enumeration_ask('Sprinkler', dict(Cloudy=T), climate).show_approx())\n",
    "\n",
    "'''\n",
    "iii. P(Cloudy| the sprinkler is running and it’s not raining) \n",
    "= ∝ * P(Sprinkler, ¬Rain | Cloudy * P(Cloudy)\n",
    "= ∝ * 0.1 * 0.2 * 0.5\n",
    "= ∝ * 0.01, 0.2\n",
    "= 0.0476, 0.952\n",
    "'''\n",
    "print(enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=F), climate).show_approx())\n",
    "\n",
    "'''\n",
    "iv.P(WetGrass | it’s cloudy, the sprinkler is running and it’s raining) = 0.99\n",
    "= 0.01, 0.99\n",
    "'''\n",
    "print(enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), climate).show_approx())\n",
    "\n",
    "\n",
    "'''\n",
    "v. P(Cloudy | the grass is not wet)\n",
    "∝ * P(Cloudy, Sprinkler, Rain, ¬WetGrass)\n",
    "= ∝ < 0.5((0.1 * 0.8 * 0.01) + (0.1 * 0.2 * 0.1) + (0.9 * 0.8 * 0.1) + (0.9 * 0.2 * 1)),\n",
    "0.5 ((0.5 * 0.2 * 0.01) + (0.5 * 0.8 * 0.1) + (0.5 * 0.2 * 0.1) + (0.5 * 0.8 * 1))\n",
    "= 0.361, 0.639\n",
    "'''\n",
    "print(enumeration_ask('Cloudy', dict(WetGrass=F), climate).show_approx())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
